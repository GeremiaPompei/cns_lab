{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LAB1 - CNS (Liquid state machine)\n",
    "Implement a Liquid State Machine model using Izhikevich neurons for the prediction of Sunspot task."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importation of needed libraries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading of dataset from the relative csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(2899,)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('solar_data.csv') as file:\n",
    "    dataset = file.readline().split(',')\n",
    "\n",
    "dataset = np.array([float(d) for d in dataset])\n",
    "\n",
    "dataset.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Slitting the dataset in input (X) and target (Y) data from the same autoregressive dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "((2898,), (2898,))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[:-1]\n",
    "Y = dataset[1:]\n",
    "\n",
    "X.shape, Y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting in train, validation and test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[(2098,), (300,), (500,)]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size = 500\n",
    "X_TR, X_TS = X[:-test_size], X[-test_size:]\n",
    "Y_TR, Y_TS = Y[:-test_size], Y[-test_size:]\n",
    "\n",
    "validation_size = 300\n",
    "X_TR, X_VL = X_TR[:-validation_size], X_TR[-validation_size:]\n",
    "Y_TR, Y_VL = Y_TR[:-validation_size], Y_TR[-validation_size:]\n",
    "\n",
    "[x.shape for x in [X_TR, X_VL, X_TS]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "Class of Liquid State Machine model. In the constructor there are parameters initialization, in `_compute_states` method the process to compute each state through the liquid, `predict` is able to take in input an input data and provide his prediction and `train` is the method able to fit the readout layer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class LSM:\n",
    "    \"\"\"\n",
    "    Class able to provide a Liquid State Machine model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_size: int = 1000,\n",
    "            e_perc: float = 0.8,\n",
    "            we_in: float = 5,\n",
    "            wi_in: float = 2,\n",
    "            we_l: float = 0.5,\n",
    "            wi_l: float = 1\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor of LSM model.\n",
    "\n",
    "        n_size: Number of Izhikevich neurons..\n",
    "        e_perc: Percentage of excitatory neurons..\n",
    "        we_in: Scaler hyperparam of input weights of excitatory neurons.\n",
    "        wi_in: Scaler hyperparam of input weights of inhibitory neurons.\n",
    "        we_l: Scaler hyperparam of liquid weights of excitatory neurons.\n",
    "        wi_l:Scaler hyperparam of liquid weights of inhibitory neurons.\n",
    "        \"\"\"\n",
    "        ne_size = int(n_size * e_perc)\n",
    "        ni_size = n_size - ne_size\n",
    "        self.a = np.concatenate((0.02 * np.ones(ne_size), 0.02 + 0.08 * np.random.rand(ni_size)))\n",
    "        self.b = np.concatenate((0.2 * np.ones(ne_size), 0.25 - 0.05 * np.random.rand(ni_size)))\n",
    "        self.c = np.concatenate((-65 + 15 * np.random.rand(ne_size) ** 2, -65 * np.ones(ni_size)))\n",
    "        self.d = np.concatenate((8 - 6 * np.random.rand(ne_size) ** 2, 2 * np.ones(ni_size)))\n",
    "        self.v = np.concatenate((-65 * np.ones(ne_size), -65 * np.ones(ni_size)))\n",
    "        self.u = self.b * self.v\n",
    "        self.U = np.concatenate((we_in * np.ones(ne_size), wi_in * np.ones(ni_size)))\n",
    "        self.S = np.concatenate(\n",
    "            (we_l * np.random.rand(ne_size + ni_size, ne_size), -wi_l * np.random.rand(ne_size + ni_size, ni_size)),\n",
    "            axis=1)\n",
    "        self.readout = np.random.rand(ne_size + ni_size)\n",
    "\n",
    "    def _compute_states(self, source: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Method able to compute states using liquid.\n",
    "\n",
    "        source: Input values to process.\n",
    "\n",
    "        returns:\n",
    "            np.array: Encoded states.\n",
    "        \"\"\"\n",
    "        states = []\n",
    "        u, v = self.u, self.v\n",
    "        for t in range(len(source)):\n",
    "            I = source[t] * self.U\n",
    "            fired = np.argwhere(v >= 30)\n",
    "            v[fired] = self.c[fired]\n",
    "            u[fired] = u[fired] + self.d[fired]\n",
    "            I = I + np.sum(self.S[:, fired], axis=1)[0]\n",
    "            for _ in range(2):\n",
    "                v = v + 0.5 * (0.04 * v ** 2 + 5 * v + 140 - u + I)\n",
    "            u = u + self.a * (self.b * v - u)\n",
    "            states.append(np.array(v >= 30, dtype=int))\n",
    "        return np.array(states)\n",
    "\n",
    "    def predict(self, source: np.array) -> np.array:\n",
    "        \"\"\"\n",
    "        Method to predict next values given an input.\n",
    "\n",
    "        source: Input values used to predict the next ones related to the next time step.\n",
    "\n",
    "        returns:\n",
    "            np.array: Predictions.\n",
    "        \"\"\"\n",
    "        states = self._compute_states(source)\n",
    "        return states @ self.readout\n",
    "\n",
    "    def train(self, source: np.array, targets: np.array, reg: float = 0.01) -> None:\n",
    "        \"\"\"\n",
    "        Method able to train the LSM model.\n",
    "\n",
    "        source: Input data.\n",
    "        targets: Target data related to source.\n",
    "        reg: Regularization hyperparam for Thikonov regularization. If it is None it is computed the simple pseudo-inverse to train the readout.\n",
    "        \"\"\"\n",
    "        states = self._compute_states(source)\n",
    "        if reg is not None:\n",
    "            self.readout = np.linalg.pinv(states.T @ states + np.eye(states.shape[1]) * reg) @ states.T @ targets\n",
    "        else:\n",
    "            self.readout = np.linalg.pinv(states) @ targets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metric\n",
    "The metric used in this regression problem is the Mean Absolute Error (MAE)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def mean_absolute_error(labels, predictions) -> float:\n",
    "    \"\"\"\n",
    "    Function able to compute the Mean Absolute Error metric.\n",
    "\n",
    "    labels: Labels given from the dataset.\n",
    "    predictions: Provided by the model.\n",
    "\n",
    "    returns:\n",
    "        float: MAE value.\n",
    "    \"\"\"\n",
    "    return abs(labels - predictions).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of hyperparameters. From these lists inside the dictionary is computed the carthesian product to have a list of dictionaries eache of them containing the configuration readable from the models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "96"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams_dol = dict(\n",
    "    n_size=[1000, 1300, 500],\n",
    "    e_perc=[0.8, 0.75],\n",
    "    we_in=[2, 5],\n",
    "    wi_in=[1, 2],\n",
    "    we_l=[0.5, 0.2],\n",
    "    wi_l=[1, 0.8],\n",
    ")\n",
    "\n",
    "hyperparams_lod = [dict(zip(hyperparams_dol.keys(), t)) for t in itertools.product(*hyperparams_dol.values())]\n",
    "\n",
    "len(hyperparams_lod)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The combination of hyperparameters values are iterated in a gridsearch to select the best hyperparameters training each new model on training set and evaluating it on validation set using the Mean Absolute Error metric."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 2, 'wi_in': 1, 'we_l': 0.5, 'wi_l': 1}\n",
      "MAE: 60.76855311959669\n",
      "2 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 2, 'wi_in': 1, 'we_l': 0.5, 'wi_l': 0.8}\n",
      "MAE: 59.77852005099334\n",
      "3 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 2, 'wi_in': 1, 'we_l': 0.2, 'wi_l': 1}\n",
      "MAE: 76.54822361767637\n",
      "4 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 2, 'wi_in': 1, 'we_l': 0.2, 'wi_l': 0.8}\n",
      "MAE: 64.35211444705101\n",
      "5 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 2, 'wi_in': 2, 'we_l': 0.5, 'wi_l': 1}\n",
      "MAE: 48.82138057539482\n",
      "6 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 2, 'wi_in': 2, 'we_l': 0.5, 'wi_l': 0.8}\n",
      "MAE: 56.36365446642191\n",
      "7 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 2, 'wi_in': 2, 'we_l': 0.2, 'wi_l': 1}\n",
      "MAE: 80.55645352293564\n",
      "8 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 2, 'wi_in': 2, 'we_l': 0.2, 'wi_l': 0.8}\n",
      "MAE: 92.8544752299755\n",
      "9 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 5, 'wi_in': 1, 'we_l': 0.5, 'wi_l': 1}\n",
      "MAE: 36.7100988184588\n",
      "10 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 5, 'wi_in': 1, 'we_l': 0.5, 'wi_l': 0.8}\n",
      "MAE: 35.20825305412598\n",
      "11 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 5, 'wi_in': 1, 'we_l': 0.2, 'wi_l': 1}\n",
      "MAE: 37.664370601980785\n",
      "12 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 5, 'wi_in': 1, 'we_l': 0.2, 'wi_l': 0.8}\n",
      "MAE: 46.20601925659765\n",
      "13 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 5, 'wi_in': 2, 'we_l': 0.5, 'wi_l': 1}\n",
      "MAE: 37.76458906890002\n",
      "14 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 5, 'wi_in': 2, 'we_l': 0.5, 'wi_l': 0.8}\n",
      "MAE: 36.13782211729488\n",
      "15 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 5, 'wi_in': 2, 'we_l': 0.2, 'wi_l': 1}\n",
      "MAE: 38.58110606873393\n",
      "16 - hyperparams: {'n_size': 1000, 'e_perc': 0.8, 'we_in': 5, 'wi_in': 2, 'we_l': 0.2, 'wi_l': 0.8}\n",
      "MAE: 36.488592526926695\n",
      "17 - hyperparams: {'n_size': 1000, 'e_perc': 0.75, 'we_in': 2, 'wi_in': 1, 'we_l': 0.5, 'wi_l': 1}\n",
      "MAE: 67.42014838751005\n",
      "18 - hyperparams: {'n_size': 1000, 'e_perc': 0.75, 'we_in': 2, 'wi_in': 1, 'we_l': 0.5, 'wi_l': 0.8}\n",
      "MAE: 56.93707242834343\n",
      "19 - hyperparams: {'n_size': 1000, 'e_perc': 0.75, 'we_in': 2, 'wi_in': 1, 'we_l': 0.2, 'wi_l': 1}\n",
      "MAE: 68.65763774412143\n",
      "20 - hyperparams: {'n_size': 1000, 'e_perc': 0.75, 'we_in': 2, 'wi_in': 1, 'we_l': 0.2, 'wi_l': 0.8}\n",
      "MAE: 64.38503268382024\n",
      "21 - hyperparams: {'n_size': 1000, 'e_perc': 0.75, 'we_in': 2, 'wi_in': 2, 'we_l': 0.5, 'wi_l': 1}\n",
      "MAE: 75.50545437506783\n",
      "22 - hyperparams: {'n_size': 1000, 'e_perc': 0.75, 'we_in': 2, 'wi_in': 2, 'we_l': 0.5, 'wi_l': 0.8}\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams, min_error = None, None\n",
    "for i, hyperparams in enumerate(hyperparams_lod):\n",
    "    print(i + 1, '- hyperparams:', hyperparams)\n",
    "    model = LSM(**hyperparams)\n",
    "    model.train(X_TR, Y_TR)\n",
    "    pred_vl = model.predict(X_VL)\n",
    "    error = mean_absolute_error(Y_VL, pred_vl)\n",
    "    print('MAE:', error)\n",
    "    if min_error is None or error < min_error:\n",
    "        min_error = error\n",
    "        best_hyperparams = hyperparams\n",
    "\n",
    "print()\n",
    "print('Best hyperparams: ', best_hyperparams)\n",
    "print('MAE:', min_error)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construction of LSM model with the best selected hyperparameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LSM(**best_hyperparams)\n",
    "\n",
    "X_TR, X_TS = X[:-test_size], X[-test_size:]\n",
    "Y_TR, Y_TS = Y[:-test_size], Y[-test_size:]\n",
    "model.train(X_TR, Y_TR)\n",
    "\n",
    "tr_pred = model.predict(X_TR)\n",
    "print('Training MAE:', mean_absolute_error(tr_pred, Y_TR))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model evaluation on test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ts_pred = model.predict(X_TS)\n",
    "print('Test MAE:', mean_absolute_error(ts_pred, Y_TS))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of function able to plot labels and predictions to compare them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_ts(title, Y, predictions):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.title(title)\n",
    "    x = list(range(len(Y)))\n",
    "    plt.plot(x, Y, label='labels')\n",
    "    plt.plot(x, predictions, label='predictions')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('sunspot')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'lsm_solarspot_plots/{title}.png')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot of comparisons between training labels and predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ts('Training labels and predictions comparisons', Y_TR, tr_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot of comparisons between test labels and predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ts('Test labels and predictions comparisons', Y_TS, ts_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
